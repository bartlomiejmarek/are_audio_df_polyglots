{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e93a88fe850787",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T21:08:32.020446Z",
     "start_time": "2024-09-04T21:08:31.028459Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.post_processing_utils import kfold_post_process, create_heatmap, prepare_df, rename, n_random_post_process\n",
    "import seaborn as sns\n",
    "# 0.0001 5e-6\n",
    "# 2.5e-6 2.5e-7\n",
    "# 0.0005 2.5e-6\n",
    "# 5e-6 2.5e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "58cc2582",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_df = pd.read_csv('../models/finetuned/evaluation_results.csv')\n",
    "base_df = pd.read_csv('../models/baselines/evaluation_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0346a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(dataframe: pd.DataFrame):\n",
    "    dataframe['y'] = dataframe['y'].apply(lambda x: literal_eval(x))\n",
    "    dataframe['y_pred'] = dataframe['y_pred'].apply(lambda x: literal_eval(x))\n",
    "    dataframe['y_pred_label'] = dataframe['y_pred_label'].apply(lambda x: literal_eval(x))\n",
    "    dataframe['evaluated languages'] = dataframe['evaluated languages'].apply(literal_eval).apply(lambda x: \"+\".join(x))\n",
    "    dataframe['model'] = dataframe['model'].apply(lambda x: rename(x))\n",
    "    dataframe['architecture'] = dataframe['model_path'].apply(lambda x: 'VITS, GriffinLIM' if 'vits' in x else 'XTTS')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bd313e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = prepare_df(base_df)\n",
    "fine_df = prepare_df(fine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ef207",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5a3fd9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_df(dataframe: pd.DataFrame, groupby_columns=['model',  'fine-tuned languages', 'evaluated languages']):\n",
    "    grouped_df = dataframe.groupby(groupby_columns).apply(lambda x:x)\n",
    "    out = {}\n",
    "    for (model, ft_lan, eval_lan, _), df in grouped_df.iterrows():\n",
    "        if (model, ft_lan, eval_lan) in out.keys():\n",
    "            out[(model, ft_lan, eval_lan)]['y'] += df['y']\n",
    "            out[(model, ft_lan, eval_lan)]['y_pred'] += df['y_pred']\n",
    "            out[(model, ft_lan, eval_lan)]['y_pred_label'] += df['y_pred_label']\n",
    "        else: \n",
    "            out[(model, ft_lan, eval_lan)] = {'y': df['y']}\n",
    "            out[(model, ft_lan, eval_lan)]['y_pred'] = df['y_pred']\n",
    "            out[(model, ft_lan, eval_lan)]['y_pred_label'] = df['y_pred_label']\n",
    "    return pd.DataFrame.from_dict(out, orient='index', columns=['y', 'y_pred', 'y_pred_label']).reset_index().rename(columns={'level_0': 'model', 'level_1': 'fine-tuned languages', 'level_2': 'evaluated languages'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bdf5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = groupby_df(base_df)\n",
    "fine_df = groupby_df(fine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fe595f7568785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:43:55.676892Z",
     "start_time": "2024-09-03T20:43:54.203094Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_df = n_random_post_process(base_df, 5, 0.75)\n",
    "ft_df = n_random_post_process(fine_df, 5, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df[list(baseline_df.select_dtypes(include='number').columns) + ['model']].groupby('model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "65dfde2c0dbc765a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:44:10.196271Z",
     "start_time": "2024-09-03T20:44:10.189985Z"
    }
   },
   "outputs": [],
   "source": [
    "languages = {\"pl\", \"de\", \"ru\", \"uk\", \"fr\", \"es\", \"it\", \"en\"}\n",
    "ft_df['fine-tuned languages'] = ft_df['fine-tuned languages'].apply(literal_eval).apply(lambda x: \" \".join(list(languages - set(x))))\n",
    "baseline_df['fine-tuned languages'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4e670618",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df = ft_df.loc[ft_df['fine-tuned languages'].apply(lambda x: len(x)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "87fde9729162405e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:44:12.239643Z",
     "start_time": "2024-09-03T20:44:12.236903Z"
    }
   },
   "outputs": [],
   "source": [
    "ft_df['model_id'] = ft_df['model'] + \" ft without \" + ft_df['fine-tuned languages']\n",
    "baseline_df['model_id'] = \"ASV trained \" + baseline_df['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8ed19b8085718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:44:16.451502Z",
     "start_time": "2024-09-03T20:44:16.443035Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_df = baseline_df.groupby(['model', 'model_id', 'fine-tuned languages', 'evaluated languages'])[baseline_df.select_dtypes(include=[np.number]).columns].mean()\n",
    "ft_df = ft_df.groupby(['model', 'model_id', 'fine-tuned languages', 'evaluated languages'])[ft_df.select_dtypes(include=[np.number]).columns].mean()\n",
    "ft_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5fa8e27229e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:44:19.683583Z",
     "start_time": "2024-09-03T20:44:19.674341Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d806af98048254b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:44:22.717925Z",
     "start_time": "2024-09-03T20:44:22.706639Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([baseline_df, ft_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c429af3b5b6fb5e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:44:26.425914Z",
     "start_time": "2024-09-03T20:44:26.420166Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9d92c59dc3829fd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:44:28.791811Z",
     "start_time": "2024-09-03T20:44:28.786160Z"
    }
   },
   "outputs": [],
   "source": [
    "df['eer'] = df['eer'].apply(lambda x: round(100*x, 2))\n",
    "df['accuracy'] = df['accuracy'].apply(lambda x: round(100*x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce35d8c13f6fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:44:34.895365Z",
     "start_time": "2024-09-03T20:44:34.881155Z"
    }
   },
   "outputs": [],
   "source": [
    "df.pivot(index=['model_id'], columns='evaluated languages', values=['eer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24efc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(df, model_name, metric='eer', metric_label=\"EER\", maximize=False, output_dir=\"results/plots\", title_prefix=\"\"):\n",
    "    dataframe = df.copy()\n",
    "    heatmap_data = dataframe.loc[dataframe['model'] == model_name].pivot(index='fine-tuned languages', columns='evaluated languages', values=metric)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    ax = sns.heatmap(\n",
    "        heatmap_data,\n",
    "        annot=True,\n",
    "        cmap=\"Blues\",\n",
    "        cbar_kws={'label': metric_label},\n",
    "        annot_kws={\"size\": 20},\n",
    "        fmt='.2f'\n",
    "    )\n",
    "    plt.xlabel('Evaluated with', fontsize=20)\n",
    "    plt.ylabel('Fine-tuned without', fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    if '-' in heatmap_data.index:\n",
    "        idx = heatmap_data.index.get_loc('-')\n",
    "        n_rows = len(heatmap_data.index)\n",
    "        n_cols = len(heatmap_data.columns)\n",
    "        ax.add_patch(plt.Rectangle((0, idx), n_cols, 1, fill=False, edgecolor='black', lw=4))\n",
    "\n",
    "        ax.vlines(x=[0, 0], ymin=0, ymax=0, colors='black', linewidth=4)\n",
    "\n",
    "    for col in heatmap_data.columns:\n",
    "        if maximize:\n",
    "            best_value = heatmap_data[col].max()\n",
    "        else:\n",
    "            best_value = heatmap_data[col].min()\n",
    "\n",
    "        # Find all indices of the best value in the column\n",
    "        best_indices = heatmap_data.index[heatmap_data[col] == best_value]\n",
    "\n",
    "        for idx in best_indices:\n",
    "            # Find row and column index to add the rectangle patch\n",
    "            row_idx = heatmap_data.index.get_loc(idx)\n",
    "            col_idx = heatmap_data.columns.get_loc(col)\n",
    "\n",
    "            # Draw a red rectangle around the best cells in the column\n",
    "            ax.add_patch(plt.Rectangle((col_idx, row_idx), 1, 1, fill=False, edgecolor='red', lw=3))\n",
    "\n",
    "    # model_name = model_name.lower()\n",
    "    \n",
    "    model_name = rename(model_name)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    cbar.set_label(metric_label, fontsize=20)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    plt.title(f'{metric_label} for {model_name}', fontsize=18)\n",
    "    print(f\"{output_dir}/{title_prefix}/{title_prefix}{model_name.replace('+', '-')}.png\")\n",
    "    # plt.savefig(f\"{output_dir}/{title_prefix}{model_name.replace('+', '-')}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "for name in df.apply(lambda x: x)['model'].unique():\n",
    "    # create_heatmap(df.loc[df['fine-tuned languages']!= '-'], name, title_prefix=\"trained\")\n",
    "    create_heatmap(df, name, title_prefix=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeb0c69",
   "metadata": {},
   "source": [
    "# EER for model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9af3b6",
   "metadata": {},
   "source": [
    "# Top 10 models for evaluated language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "k_base = n_random_post_process(base_df, 5, 0.8)\n",
    "k_ft = n_random_post_process(fine_df, 5, 0.8)\n",
    "cols = ['model', 'fine-tuned languages', 'evaluated languages', 'eer']\n",
    "k_base['model'] = k_base['model'] + ' trained on ASV'\n",
    "k_ft = k_ft.loc[k_ft['fine-tuned languages'].apply(lambda x: len(x)) > 4]\n",
    "\n",
    "dataframe = pd.concat([k_base[cols], k_ft[cols]])\n",
    "dataframe['fine-tuned languages'] = dataframe['fine-tuned languages'].apply(literal_eval).apply(lambda x: \"+\".join(x))\n",
    "\n",
    "dataframe['model'] = dataframe.apply(lambda x: x['model'] + ' fine-tuned with ' + x['fine-tuned languages'] if \"ASV\" not in x['model'] else x['model'], axis=1)\n",
    "dataframe['model'] = dataframe['model'].apply(rename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9d3529ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.groupby(['model', 'fine-tuned languages', 'evaluated languages']).agg(lambda x: f\"{100*x.mean():.2f} Â± {100*x.std():.2f}\")\n",
    "\n",
    "dataframe: DataFrame  = dataframe.pivot_table(values='eer', index='model', columns=['evaluated languages'], aggfunc=''.join, fill_value='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8227fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan = 'en'\n",
    "dataframe[lan].apply(lambda x: float(x.split(' ')[0]) if x != '-' else np.inf).sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan = 'de'\n",
    "dataframe[lan].apply(lambda x: float(x.split(' ')[0]) if x != '-' else np.inf).sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan = 'fr'\n",
    "dataframe[lan].apply(lambda x: float(x.split(' ')[0]) if x != '-' else np.inf).sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4adb04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan = 'it'\n",
    "dataframe[lan].apply(lambda x: float(x.split(' ')[0]) if x != '-' else np.inf).sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94185867",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan = 'es'\n",
    "dataframe[lan].apply(lambda x: float(x.split(' ')[0]) if x != '-' else np.inf).sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57470a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan = 'pl'\n",
    "dataframe[lan].apply(lambda x: float(x.split(' ')[0]) if x != '-' else np.inf).sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan = 'uk'\n",
    "dataframe[lan].apply(lambda x: float(x.split(' ')[0]) if x != '-' else np.inf).sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c069bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan = 'ru'\n",
    "dataframe[lan].apply(lambda x: float(x.split(' ')[0]) if x != '-' else np.inf).sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9acb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['en', 'de']\n",
    "langs = ['fr', 'es', 'it']\n",
    "langs = ['pl', 'ru', 'uk']\n",
    "\n",
    "dataframe[langs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41120f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['en', 'de']\n",
    "# langs = ['fr', 'es', 'it']\n",
    "# langs = ['pl', 'ru', 'uk']\n",
    "caption = \"Baseline\"\n",
    "latex_code = dataframe.loc[dataframe.index.str.contains('ASV')][langs].to_latex(index=True, column_format='l|ccc', float_format=\"%.2f\", caption=caption, label=f\"tab:{'_'.join(langs)}\")\n",
    "latex_code = latex_code.replace(\"trained on ASV\", \"&\")\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['en', 'de']\n",
    "# langs = ['fr', 'es', 'it']\n",
    "# langs = ['pl', 'ru', 'uk']\n",
    "caption = \"The mean EER scores with standard deviation for $K$-fold tests for $K=5$ for the Germanic languages tested on ASV-trained models.\"\n",
    "latex_code = dataframe.loc[dataframe.index.str.contains('ASV')][langs].to_latex(index=True, column_format='l|cc', float_format=\"%.2f\", caption=caption, label=f\"tab:{'_'.join(langs)}\")\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b31e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['en', 'de']\n",
    "caption = \"The mean EER scores with standard deviation for $K$-fold tests for $K=5$ for the Germanic languages tested on ASV-trained models fine-tuned with samples generated using $D_{ft}$ subset for the specific language.\"\n",
    "\n",
    "model, i = 'LFCC', 2\n",
    "\n",
    "latex_code =  dataframe.loc[(~dataframe.index.str.contains('ASV')) & (dataframe.index.str.contains(model))][langs].to_latex(index=True, column_format='l|ccc', float_format=\"%.2f\", caption=caption, label=f\"tab:{'_'.join(langs)}\")\n",
    "print(latex_code.replace(f\"{model} fine-tuned with \", f\"{''.join(langs)}&\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['fr', 'es', 'it']\n",
    "caption = \"The mean EER scores with standard deviation for $K$-fold tests for $K=5$ for the Germanic languages tested on ASV-trained models fine-tuned with samples generated using $D_{ft}$ subset for the specific language.\"\n",
    "\n",
    "latex_code =  dataframe.loc[(~dataframe.index.str.contains('ASV')) & (dataframe.index.str.contains(model))][langs].to_latex(index=True, column_format='l|ccc', float_format=\"%.2f\", caption=caption, label=f\"tab:{'_'.join(langs)}\")\n",
    "print(latex_code.replace(f\"{model} fine-tuned with \", f\"{''.join(langs)}&\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
